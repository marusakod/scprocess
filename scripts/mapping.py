import os
import argparse
import pathlib
import subprocess

# set up
import collections
import tempfile
import gc
import random
import json
import polars as pl
import numpy as np

def map_fastqs_to_counts(run, af_dir, demux_type, what, af_home_dir, 
    where, R1_fs, R2_fs, threads, t2g_f, index_dir, wl_lu_f, tenx_chemistry = None, exp_ori = None, whitelist_f = None):
  # make output directory, in subdirectory if multiplexed samples
  out_dir   = f"{af_dir}/af_{run}"
  if demux_type == "hto":
    if what == "rna":
      out_dir = f"{out_dir}/rna"
    elif what == "hto":
      out_dir = f"{out_dir}/hto"
  os.makedirs(out_dir, exist_ok = True)
  print('made out_dir')

  # set up simpleaf
  os.environ["ALEVIN_FRY_HOME"] = af_home_dir
  subprocess.run(["simpleaf", "set-paths"])

  # if arvados, download to temp files
  on_arvados  = not os.path.exists(where)
  if on_arvados:
    # set up tmp directory
    tmp_dir     = f"{af_dir}/.tmp_fastqs_{run}_{what}"
    prefix      = f"{run}_{what}"
    os.makedirs(tmp_dir, exist_ok = True)

    # download files from Arvados
    print('downloading files from arvados')
    arv_uuid    = where
    R1_fs       = [ _download_arvados_file_as_tempfile(arv_uuid, f, tmp_dir, prefix, i, "R1", threads) for i, f in enumerate(R1_fs) ]
    R2_fs       = [ _download_arvados_file_as_tempfile(arv_uuid, f, tmp_dir, prefix, i, "R2", threads) for i, f in enumerate(R2_fs) ]
  else:
    R1_fs       = [ os.path.join(where, f) for f in R1_fs]
    R2_fs       = [ os.path.join(where, f) for f in R2_fs]

  if tenx_chemistry is None: # and exp_ori and whitelist_f
    wl_overlap_dt = _get_whitelist_overlap(R1_fs, wl_lu_f)
    # check for which barcode whitelist the overlap is the highest
    max_overlap = max(wl_overlap_dt)
    if max_overlap < 0.7:
      raise Warning(f'Maximum overlap ob barcodes is {max_overlap:.1%}, 10x chemistry guess might be incorrect')
    
    sel_wl_dt = wl_overlap_dt.filter(pl.col('overlap') == max_overlap)
    whitelist_f = sel_wl_dt['whitelist_f'][0]
    if sel_wl_dt.height == 1:
      sample_chem = sel_wl_dt['chemistry'][0]
      if sample_chem in ['3v2', '5v1', '5v2']:
        tenx_chemistry = '10xv2' 
      else: 
        tenx_chemistry = '10xv3'
      
      # get expected orientation
      if sample_chem in ['5v1', '5v2', '5v3']:
        exp_ori = 'rc'
      else:
        exp_ori = 'fw'
    
    else: # if selected whitelist corresponds to multiple chemistries with different orrientation, do mapping on downsampled data
      _subset_fastqs(R1_fs, R2_fs)
      # need to map downsampled fastqs as well
      ori_guess = _infer_read_orientation(out_dir)
      exp_ori   = ori_guess
      tenx_chemistry = tenx_chemistry # this is not correct, somehow get chemistry

  # do quantification
  simpleaf_cmd  = [
    "simpleaf", "quant", 
    "--reads1", ",".join(R1_fs), 
    "--reads2", ",".join(R2_fs),
    "--threads", f"{threads}", 
    "--index", index_dir, 
    "--chemistry", tenx_chemistry, 
    "--resolution", "cr-like", 
    "--expected-ori", exp_ori, 
    "--t2g-map", t2g_f, 
    "--unfiltered-pl", whitelist_f,
    "--min-reads", "1", 
    "--output", out_dir
    ]
  if what == "hto":
    simpleaf_cmd.append("--no-piscem")
  subprocess.run(simpleaf_cmd)

  # tidy up any temp fastq files
  if on_arvados:
    for f in R1_fs:
      os.unlink(f)
    for f in R2_fs:
      os.unlink(f)
    os.rmdir(tmp_dir)


def _download_arvados_file_as_tempfile(arv_uuid, f, tmp_dir, prefix, i, read, threads):

  # create a temporary file to store the data
  temp_file   = pathlib.Path(tmp_dir) / f"{prefix}.{i}.{read}.fastq.gz"

  # write the contents of the arvados file-like object to the temporary file
  print(f"  downloading {f} from arvados as tmp file {temp_file.name}")
  subprocess.run(["arv-get", f"{arv_uuid}/{f}", str(temp_file), "--threads", str(threads)])

  return str(temp_file)


def _subset_fastqs(R1_fs, R2_fs, smpl_size = 100000):
  # check how many R1 + R2 file pairs
  if len(R1_fs) > 1:
    random.seed(12346)
    idx = random.sample(range(len(R1_fs)), 1)[0] # this is probably not necessary 
    R1_f = R1_fs[idx]
    R2_f = R2_fs[idx]
  else:
    R1_f = R1_fs[0]
    R2_f = R2_fs[0]
  
  # get names for downsampled files
  R1_f_base = os.path.basename(R1_f)
  R2_f_base = os.path.basename(R2_f)
  
  # get fastq dir
  fastq_dir = os.path.dirname(R1_f)
  sub_R1_f = f'{fastq_dir}/dowsampled_{R1_f_base}'
  sub_R2_f = f'{fastq_dir}/downsampled_{R2_f_base}'
  subprocess.run(["seqkit", "head", "-n", f"{smpl_size}", R1_f, "-o", sub_R1_f], check=True)
  subprocess.run(["seqkit", "head", "-n", f"{smpl_size}", R2_f, "-o", sub_R2_f], check=True)
  
  return

# af_res_dir should be a directory where temporary alevin inputs for inference of chemistry are stored
def _infer_read_orientation(af_res_dir):
  
  # check the meta_info.json generated by simpleaf
  json_path = os.path.join(af_res_dir, "af_quant", "meta_info.json")
  with open(json_path) as f:
    data = json.load(f)
    pct_mapped = data.get("percent_mapped", 0)
    
    # high mapping rate (>50%) --> mapping with fw seems correct --> likely 3'
    if pct_mapped >= 50.0:
      ori_guess = "fw"
    # low mapping rate (<15%) --> highly likely mapping should've been with rc --> likely 5'
    elif pct_mapped <= 15.0:
      ori_guess = "rc"
    # hmm 
    else:
      ori_guess = "fw" 
      
    return ori_guess

  # pick one random pair and save subsampled data into a new files
  # check if that has enough reads and if not subsample another pair (probably not necessary)
  # do mapping of that subsampled pair
  # also extract just barcodes from the subsampled data for version mapping
  # remove temporary subsampled files
  # somehow also consider multiplexing information

def _get_whitelist_overlap(R1_f, wl_lu_f, sample_size = 100000):
  # randomly pick one R1 file to extract barcodes from
  random.seed(1234)
  R1_f = random.sample(R1_f, 1)
    
  # get all barcode whitelist files
  wl_dt  = pl.read_csv(wl_lu_f).select(['chemistry', 'barcodes_f'])
  wl_fs  = list(set(wl_dt['barcodes_f'].to_list()))
    
  # calculate overlap of barcodes with each whitelist for all R1_fs
  overlap_dict = {"barcodes_f": [], "overlap": []}

  print(f'Extracting barcodes from {R1_f}')
  spell     = f"seqkit head -n {sample_size} {R1_f} | seqkit subseq -r 1:16"
  spell_res = subprocess.run(spell, shell=True, capture_output=True, text=True)
  spell_out = spell_res.stdout
  barcodes  = _extract_raw_seqs_from_fq(spell_out)
  barcodes  = np.unique(barcodes)
  n_bcs     = len(barcodes)
  print(f'Number of unique barcodes: {n_bcs}')

  for wl_f in wl_fs:
    wl = np.loadtxt(wl_f, dtype = 'str')
    overlap = sum(np.in1d(barcodes, wl)) / n_bcs
    overlap_dict['barcodes_f'].append(wl_f)
    overlap_dict['overlap'].append(overlap)

  # merge overlaps with chemistries
  overlap_dt = pl.DataFrame(overlap_dict)
  full_dt    = wl_dt.join(overlap_dt, on = 'barcodes_f', coalesce=True, how = 'full')

  return full_dt
    

# A FASTQ file contains sequences and their associated quality scores. Each entry is structured as
#@SEQ_ID - identifier for the sequencing read
#SEQUENCE - DNA sequence
#+ - separator line (empty or SEQ_ID)
#QUALITY - quality score string for the sequence
# this function extracts DNA sequences from each entry of a FASTQ file
def _extract_raw_seqs_from_fq(fastq_all):
    entries = fastq_all.strip().split('\n@')[0:]
    seqs = []
    for e in entries:
        ls = e.split('\n')
        if len(ls) > 1:
            seqs.append(ls[1])
    return seqs     


if __name__ == "__main__":
  # get arguments
  parser  = argparse.ArgumentParser()
  parser.add_argument("run", type=str)
  parser.add_argument("--af_dir", type=str)
  parser.add_argument("--demux_type", type=str)
  parser.add_argument("--what", default="rna", type=str, choices=["rna", "hto"])
  parser.add_argument("--af_home_dir", type=str)
  parser.add_argument("--where", type=str)
  parser.add_argument("--R1_fs", nargs="+")
  parser.add_argument("--R2_fs", nargs="+")
  parser.add_argument("--threads", default=1, type=int)
  parser.add_argument("--af_index_dir", type=str)
  parser.add_argument("--tenx_chemistry", type=str)
  parser.add_argument("--exp_ori", type=str)
  parser.add_argument("--whitelist_f", type=str)

  # set up some locations
  args    = parser.parse_args()
  if args.what == 'hto':
    t2g_f     = f"{args.af_dir}/t2g_hto.tsv"
    index_dir = f"{args.af_dir}/hto_index"
  else:
    t2g_f     = f"{args.af_index_dir}/index/t2g_3col.tsv"
    index_dir = f"{args.af_index_dir}/index"

  # run
  map_fastqs_to_counts(args.run, args.af_dir, args.demux_type, args.what, args.af_home_dir, 
    args.where, args.R1_fs, args.R2_fs, args.threads, args.af_index_dir, args.tenx_chemistry, 
    args.exp_ori, args.whitelist_f, t2g_f, index_dir)
