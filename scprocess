#!/usr/bin/env python3

# PATH="${PATH:+${PATH}:}/home/macnairw/packages/scProcess/scprocess.py"

# import utils
import argparse
import os
import sys
import textwrap
import yaml
import pathlib
import polars as pl
import glob
import subprocess
import shlex
import filecmp

# import scprocess functions
scprocess_dir  = os.path.dirname(__file__)
sys.path.append(os.path.join(scprocess_dir, 'scripts'))
import scprocess_utils


# scprocess setup
def run_setup(scprocess_dir, snakefile, extraargs):
  print('doing some checks on inputs')
 
  # get scprocess_data_dir; should be defined in .bashrc
  scdata_dir = os.getenv('SCPROCESS_DATA_DIR')
  if scdata_dir:
    print(f'SCPROCESS_DATA_DIR is set to: {scdata_dir}')
  else:
    raise ValueError('SCPROCESS_DATA_DIR is not defined in .bashrc')
  
  # check that scdata_dir is a directory
  if not os.path.isdir(scdata_dir):
    raise FileNotFoundError("SCPROCESS_DATA_DIR is not a directory")
  
  # check that config file exists
  setup_f     = scdata_dir / 'scprocess_setup.yaml'
  if not os.path.exists(setup_f):
    raise FileNotFoundError(f"Config file {setup_f} does not exist")
  
  # get validated config
  with open(setup_f, "r") as f:
    setup_cfg   = yaml.safe_load(f)
  schema_f    = scprocess_dir / "resources/schemas/setup.schema.json"
  if not schema_f.is_file():
    raise FileNotFoundError("setup schema file not found")
  setup_cfg   = scprocess_utils.check_setup_config(setup_cfg, schema_f, scdata_dir, scprocess_dir)
  
  # add snakemake profile flag if specified
  if "profile_dir" in setup_cfg['user']:
    extraargs.extend([' --workflow-profile ', setup_cfg['user']['profile_dir']])
    
  # change scprocess directory
  os.chdir(scprocess_dir)

  # set up commands
  cmd_list    = ['snakemake',
    "--snakefile", str(snakefile),
    "--configfile", str(setup_f.resolve()),
    "--rerun-triggers", "mtime", "params",
    "--rerun-incomplete", "--verbose", "--use-conda"
  ]
  cmd_list.extend(extraargs)

  # run
  print("starting scprocess setup")
  cmd_str = " ".join(map(str, cmd_list))
  print(f"running command:\n{cmd_str}")
  subprocess.run( cmd_list, check = True )


# scprocess newproj
def new_proj(sc_dir, name, where, create_subdirs, create_config):
  # define template path
  src_dir   = os.path.join(sc_dir, "resources", "newproj_files")
  proj_dir  = os.path.join(where, name)

  # check if where is a valid path
  if not os.path.exists(where):
    raise ValueError(f"Error: The specified directory '{where}' does not exist.")
  if not os.path.isdir(where):
    raise ValueError(f"Error: '{where}' is not a directory.")

  # check if project already exists
  if os.path.exists(proj_dir):
    raise ValueError("project already exists")

  # create project directory
  os.mkdir(proj_dir)
  os.chdir(proj_dir)

  # create required directories
  dir_ls = ['.log', 'data', 'code', 'analysis', 'output', 'public']
  for d in dir_ls:
    os.mkdir(d)

  # create additional subdirectories if requested
  if create_subdirs:
    os.mkdir(os.path.join(proj_dir, 'data', 'fastqs'))
    os.mkdir(os.path.join(proj_dir, 'data', 'metadata'))

  # define required files and locations
  f_ls = ['_workflowr.yml', '.gitignore', '.gitattributes',
      '_site.yml', 'custom.css', 'about.Rmd', 'index.Rmd', 'license.Rmd', '.nojekyll']
  loc_ls = ['.', '.', '.', 'analysis', 'analysis', 'analysis', 'analysis', 'analysis', 'public']
  assert len(f_ls) == len(loc_ls)

  # copy template files
  for f, l in zip(f_ls, loc_ls):
    subprocess.call(['cp', os.path.join(src_dir, f), os.path.join(proj_dir, l, f)])

  # Modify _site.yml
  site_f = os.path.join(proj_dir, 'analysis', '_site.yml')
  with open(site_f, 'r') as file:
    site_yml_txt = file.read()
  site_yml_txt = site_yml_txt.replace("proj_template", name)
  with open(site_f, 'w') as file:
    file.write(site_yml_txt)

  # copy project file
  proj_ext = '.Rproj'
  subprocess.call(['cp', os.path.join(src_dir, "proj_template" + proj_ext), os.path.join(proj_dir, name + proj_ext)])

  # create .Rprofile file
  rprofile_txt = """## This makes sure that R loads the workflowr package
  ## automatically, every time the project is loaded
  if (requireNamespace("workflowr", quietly = TRUE)) {
    message("Loading .Rprofile for the current workflowr project")
    library("workflowr")
  } else {
    message("workflowr package not installed, please run install.packages(\'workflowr\') to use the workflowr functions")
  }
  """
  rprofile_txt  = textwrap.dedent(rprofile_txt)
  rprofile_f    = os.path.join(proj_dir, '.Rprofile')
  with open(rprofile_f, "w") as file:
    file.write(rprofile_txt)

  # create config file if requested
  if create_config is not None:
    # import something we need
    from datetime import date

    # set up files etc
    config_f    = os.path.join(proj_dir, f"config-{name}.yaml")
    today       = date.today()
    date_stamp  = today.strftime('%Y-%m-%d')
    fastq_dir   = 'data/fastqs' if create_subdirs else ''
    meta_dir    = 'data/metadata' if create_subdirs else ''

    # check that config file exists
    scdata_dir  = os.getenv('SCPROCESS_DATA_DIR')
    setup_f     = os.path.join(scdata_dir, 'scprocess_setup.yaml')
    if not os.path.exists(setup_f):
      raise FileNotFoundError(f"Config file {setup_f} does not exist")

    # get validated config
    with open(setup_f, "r") as f:
      setup_cfg   = yaml.safe_load(f)
    schema_f    = scprocess_dir / "resources/schemas/setup.schema.json"
    if not schema_f.is_file():
      raise FileNotFoundError("setup schema file not found")
    setup_cfg   = scprocess_utils.check_setup_config(setup_cfg, schema_f, scdata_dir, scprocess_dir)

    # get name and affiliation from setup config if they are there
    your_name   = setup_cfg["user"].get("your_name", "")
    affiliation = setup_cfg["user"].get("affiliation", "")

    # define config text
    proj_txt    = f"""
      # for details on how to fill out the config file, please see the following link:
      # https://macnairw.pages.roche.com/scprocess/reference
      project:
        proj_dir: {proj_dir}
        fastq_dir: {fastq_dir}
        full_tag: {name}
        short_tag:
        your_name: {your_name}
        affiliation: {affiliation}
        sample_metadata: {meta_dir}/
        species:
        date_stamp: "{date_stamp}"
      """
    if "sc" in create_config:
      qc_txt = """qc:
        qc_max_mito: 0.1
        qc_min_splice: 0.10
        qc_max_splice: 0.99
      """
    if "sn" in create_config:
      qc_txt = """qc:
        qc_max_mito: 0.1
        qc_max_splice: 0.75
      """
    if "multiplex" in create_config:
      multi_txt = """multiplexing:
        demux_type:
      """
    else:
      multi_txt = ""

    # join together
    config_txt  = proj_txt + multi_txt + qc_txt
    config_txt  = textwrap.dedent(config_txt).strip()

    # write to file
    with open(config_f, "w") as file:
      file.write(config_txt)

  return


# scprocess run
def run_scprocess(sc_dir, configfile, snakefile, rule, extraargs, noindex):
  print('doing some checks on inputs')

  # housekeeping
  config_path   = pathlib.Path(configfile).resolve()
  scprocess_dir = pathlib.Path(__file__).parent
  os.chdir(scprocess_dir)

  # do some checks
  scdata_dir, extraargs = scprocess_utils.check_setup_before_running_scprocess(scprocess_dir, extraargs)
  lm_f          = scprocess_dir / "resources/snakemake/resources_lm_params_2025-12-16.csv"

  # get validated config
  with open(config_path, "r") as f:
    config        = yaml.safe_load(f)
  schema_f      = scprocess_dir / "resources/schemas/config.schema.json"
  if not schema_f.is_file():
    raise FileNotFoundError("schema file not found")
  config        = scprocess_utils.check_config(config, schema_f, scdata_dir, scprocess_dir)

  # get lists of parameters
  RUN_PARAMS, _       = scprocess_utils.get_run_parameters(config, scdata_dir)
  RUNS                = list(RUN_PARAMS.keys())
  BATCH_PARAMS, BATCH_VAR, SAMPLES = scprocess_utils.get_batch_parameters(config, RUNS, scdata_dir)
  BATCHES             = list(BATCH_PARAMS.keys())
  _                   = scprocess_utils.prep_resource_params(config, schema_f, lm_f, RUN_PARAMS, BATCHES)
  _, _                = scprocess_utils.get_runs_to_batches(config, RUNS, BATCHES, BATCH_VAR)
  _                   = scprocess_utils.get_labeller_parameters(config, schema_f, scdata_dir)

  # print which files will be processed
  print(f"\nprocessing {len(BATCHES)} samples:")
  print('  ' + ', '.join(BATCHES))

  # assemble what we'll do
  cmd_list    = ["snakemake", 
    "--snakefile", str(snakefile),
    "--configfile", str(config_path),
    "--config", f"scprocess_dir={str(scprocess_dir)}",
    "--rerun-triggers", "mtime", "params", "--rerun-incomplete", "--verbose",
    "--software-deployment-method", "conda",
    "--use-apptainer", "--apptainer-args", f"--cleanenv --nv --bind /tmp,{config['project']['proj_dir']}",
    *extraargs,
    rule]
  cmd_str = " ".join(map(str, cmd_list))
  print(f"snakemake command:\n{cmd_str}")
  subprocess.run( cmd_list, check = True )

  # render index if requested
  if not noindex and "-np" not in extraargs:
    _render_index(scprocess_dir, config)
 
  return


def _render_index(scprocess_dir, config):
  # 1. Locate the template and script
  template_f    = (scprocess_dir / "resources/rmd_templates/index.Rmd.template").resolve()
  render_script = scprocess_dir / "scripts/render_htmls.R"

  # unpack from config    
  proj_dir      = config['project']['proj_dir']
  rmd_dir       = proj_dir / "analysis"
  docs_dir      = proj_dir / "public"

  # 2. Build the R snippet (escaping quotes where necessary)
  r_code = f"""
  source('{render_script}'); 
  render_html(
    rule_name   = 'index', 
    proj_dir    = '{proj_dir}', 
    your_name   = '{config['project']['your_name']}', 
    affiliation = '{config['project']['affiliation']}',
    docs_dir    = '{docs_dir}', 
    short_tag   = '{config['project']['short_tag']}', 
    full_tag    = '{config['project']['full_tag']}',  
    date_stamp  = '{config['project']['date_stamp']}',
    mkr_sel_res = '{config['marker_genes']['mkr_sel_res']}', 
    temp_f      = '{template_f}',
    rmd_f       = '{rmd_dir}/index.Rmd'
  )
  """

  # get env
  conda_dir   = scprocess_dir / ".snakemake/conda"
  rlibs_f     = scprocess_dir / 'envs/rlibs.yaml'
  env_path    = _find_env_path_from_yaml(scprocess_dir, rlibs_f)  
  if not env_path:
    raise RuntimeError("Could not find a Snakemake conda environment matching rlibs. "
      "Has the pipeline run successfully at least once?")

  # actually do it
  print(f"rendering html index")  
  cmd = [
    "conda", "run", "--prefix", env_path,
    "Rscript", "--vanilla", "-e", r_code
  ]
  
  return subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)


def _find_env_path_from_yaml(scprocess_dir, source_yaml):
  conda_dir   = scprocess_dir / ".snakemake" / "conda"
  source_yaml = source_yaml.resolve()

  if not os.path.exists(conda_dir):
    return None

  # Look for all .yaml files in the snakemake conda folder
  for f in os.listdir(conda_dir):
    if f.endswith(".yaml"):
      potential_match = conda_dir / f
      
      # Compare the content of your rlibs.yaml with Snakemake's copy
      if filecmp.cmp(source_yaml, potential_match, shallow=False):
        # The env directory is the filename minus the ".yaml" extension
        env_path = conda_dir / f.replace(".yaml", "")
        if env_path.is_dir():
          return env_path

  return None


# scprocess plotknee
def plot_interactive_knee(config_f, knee_f, sample):
  # check we can find the file
  if args.kneefile:
    knee_f      = pathlib.Path(args.kneefile)
    if not knee_f.is_file():
      raise FileNotFoundError(f"Specified knee file doesn't exist. Check for typos, but", 
        " if the file doesn't exist you can generate the file by running the rule 'mapping'")
  else:
    # open config file and get project directory
    with open(config_f) as f:
      config = yaml.load(f, Loader=yaml.FullLoader)
    
    # get required variables
    proj_dir    = pathlib.Path(config['project']['proj_dir'])
    short_tag   = config['project']['short_tag']
    date_stamp  = config['project']['date_stamp']

    # use them to define a knee file to use
    knee_f      = proj_dir / f"output/{short_tag}_mapping/af_{sample}" / f"knee_plot_data_{sample}_{date_stamp}.csv.gz"
    if not knee_f.is_file():
      knee_f      = proj_dir / f"output/{short_tag}_mapping/af_{sample}/rna" / f"knee_plot_data_{sample}_{date_stamp}.csv.gz"
    if not knee_f.is_file():
      raise FileNotFoundError(f"Knee file for {sample} doesn't exist. You can generate it ", 
        "by running the rule 'mapping'")

  print('importing modules for plotting knees')
  import gzip
  import plotly.express as px
  from plotly.offline import plot

  # read knee file
  knee_df = pl.read_csv(knee_f, schema_overrides = {'rank': pl.Float32} )

  # make plot
  fig = px.scatter(
    knee_df.to_pandas(),
    x='rank',
    y='total',
    title=f"sample_id: {sample}",
    log_x=True, 
    log_y=True, 
    labels={'rank': 'barcode rank', 'total': 'library size'}
  )
  fig.update_traces(marker=dict(color='black', size=5))

  # update the layout to set background colors
  fig.update_layout(
    plot_bgcolor  = 'white', 
    paper_bgcolor = 'white',
    xaxis     = dict( gridcolor = '#e5e7e9', zerolinecolor = '#e5e7e9' ),
    yaxis     = dict( gridcolor = '#e5e7e9', zerolinecolor = '#e5e7e9' ),
    autosize  = False,
    width     = 1200,
    height    = 700
  )

  # save plot as html file
  knee_dir  = os.path.dirname(knee_f)
  plot_f    = os.path.join(knee_dir, f"scprocess_knee_plot_{sample}.html")
  fig.write_html(plot_f)
  # plot(fig, auto_open=True)

  # tell user where knee plot was saved
  print(f"interactive knee plot saved here:\n  {plot_f}")


def show_version_and_hpc_info(sc_dir):
  """Display scprocess version and HPC configuration details."""
  
  # Get version
  version_f   = sc_dir / "VERSION"
  version     = "unknown"
  if version_f.exists():
    with open(version_f, "r") as f:
      version = f.read().strip()
  
  print(f"\nscprocess version: {version}")
  
  # Get HPC information from scprocess_setup.yaml if available
  scdata_dir  = os.getenv('SCPROCESS_DATA_DIR')
  if not scdata_dir:
    print("\nNo HPC configuration found (SCPROCESS_DATA_DIR not set)")
    return
  setup_f     = pathlib.Path(scdata_dir) / 'scprocess_setup.yaml'
  if not setup_f.exists():
    print(f"\nNo HPC configuration found ({setup_f} does not exist)")
    return
  
  # see if we can read the config and display some of the details in a user-friendly way
  try:
    with open(setup_f, "r") as f:
      setup_cfg = yaml.safe_load(f)

    # Display user information
    if setup_cfg.get('user'):
      user_info = setup_cfg['user']
      print("")
      if user_info.get('your_name'):
        print(f"  User: {user_info['your_name']}")
      if user_info.get('affiliation'):
        print(f"  Affiliation: {user_info['affiliation']}")
  
      if user_info.get('profile'):
        print("\nHPC Configuration:")
        profile_name = user_info['profile']
        print(f"  Profile: {profile_name}")
        # Try to display profile config details
        profile_f = sc_dir / 'profiles' / profile_name / 'config.yaml'
        if profile_f.exists():
          with open(profile_f, "r") as f:
            profile_cfg = yaml.safe_load(f)
          if profile_cfg:
            print(f"  Location: {profile_f}")
            if profile_cfg.get('executor'):
              print(f"  Executor: {profile_cfg['executor']}")
      
    else:
      print("  No user information configured")
    
    print("\nReference genomes:")
    
    # Display reference genomes
    if setup_cfg.get('genomes'):
      genomes = setup_cfg['genomes']
      if genomes.get('tenx'):
        print(f"  10x:")
        for genome in genomes['tenx']:
          print(f"    - {genome['name']}")
      if genomes.get('custom'):
        print(f"  custom:")
        for genome in genomes['custom']:
          print(f"    - {genome['name']}")
    
  except Exception as e:
    print(f"\nWarning: Could not read HPC configuration: {e}")


if __name__ == '__main__':
  # define arguments
  parser      = argparse.ArgumentParser(
    description = 'snakemake workflows for processing single cell RNAseq data.'
  )
  subparsers  = parser.add_subparsers(dest='subcommand', help="scprocess subcommands:", required=False)

  # subparser for the 'setup' subcommand
  setup_prsr  = subparsers.add_parser('setup', help="do setup for scprocess")

  # add arguments for setup
  setup_prsr.add_argument("-n", "--dry-run", action="store_true", 
    help = '''
      "Dry run" execution, i.e. snakemake will print out what it would do for the setup step, but not actually do it.
      ''')
  setup_prsr.add_argument("-E", "--extraargs", action="store", nargs=1, type=str,
    help = '''
      Extra snakamake arguments. Must be provided within quotes and use an equals sign.
      For example, to have a dryrun: -E="-n"
      ''')

  # subparser for the 'plotknee' subcommand
  newprj_prsr = subparsers.add_parser('newproj', help="create new project folder with structure that scprocess expects")

  # add arguments for new project
  newprj_prsr.add_argument('name', type=str, help="Name of the project")
  newprj_prsr.add_argument('-w', '--where', type=str, default=os.getcwd(), help="Where to create the project (default: current directory)")
  newprj_prsr.add_argument('-s', '--sub', action='store_true', help="Create data/fastqs and data/metadata subdirectories")
  newprj_prsr.add_argument('-c', '--config', type=str, choices = ["sc", "sn", "multiplex"], nargs="+",
    help="Create a blank config.yml file with required scprocess parameters. Users must specify at least one option from: sc (single cell); sn (single nuclei); multiplex.")

  # subparser for the 'run' subcommand
  run_prsr    = subparsers.add_parser('run', help="run scprocess")

  # add arguments for scprocess
  run_prsr.add_argument("configfile", type = str, 
    help = "Required. YAML file specifying what you want to run, and any non-default parameters")
  run_prsr.add_argument("-r", "--rule", type = str, default = "all",
    choices = [
        "all", "mapping", "ambient", "demux", "qc", "hvg", "integration", "marker_genes", "label_celltypes", "zoom"
        ],
    help = '''
      Leave empty to run the whole workflow, or alternatively select the rule you want to run.
      ''')
  run_prsr.add_argument("-n", "--dry-run", action="store_true", 
    help = '''
      "Dry run" execution, i.e. snakemake will print out what it would do, but not actually do it.
      ''')
  run_prsr.add_argument("-E", "--extraargs", action="store", nargs=1, type=str,
    help = '''
      Extra snakamake arguments. Must be provided within quotes and given after an equals sign. 
      For example, to reduce outputs from snakemake: -E="--quiet"
      ''')
  run_prsr.add_argument("--unlock", action="store_true", 
    help = '''
      When an scprocess run is stopped before it is finished, the snakemake directory
      may be locked. If you get an error message saying that it is locked, use this
      option to unlock it, then run scprocess as normal.
      ''')
  run_prsr.add_argument("--noindex", action='store_true', 
    help = "")

  # subparser for the 'plotknee' subcommand
  knee_parser = subparsers.add_parser('plotknee', help="save interactive knee plot for a specified sample, to help specify custom parameters")

  # define arguments
  knee_parser.add_argument("sample", type = str, help = 'Sample to be plotted.')
  group       = knee_parser.add_mutually_exclusive_group()
  group.add_argument("-c", "--configfile", type = str, nargs = '?', default = None,
    help = "Path to configuration file used for running scprocess. ")
  group.add_argument("-k", "--kneefile", type = str, default = None,
    help = "Path to knee file")

  # define scprocess directory
  sc_dir    = pathlib.Path(os.path.dirname(os.path.realpath(__file__)))

  # Parse the arguments
  args      = parser.parse_args()

  # If no subcommand provided, show version and HPC info
  if args.subcommand is None:
    show_version_and_hpc_info(sc_dir)
  
  # create new project folder
  elif args.subcommand == "setup":
    # select snakefile corresponding to workflow
    snakefile   = sc_dir / "rules/setup.smk"

    # sort out extra arguments
    extraargs   = []
    if args.extraargs:
      extraargs.append(args.extraargs[0])
    if args.dry_run:
      extraargs.append("-np")
    
    # call bsub thing
    run_setup(sc_dir, snakefile, extraargs)

  elif args.subcommand == "newproj":
    # make new project directory
    if not args.config is None:
      if ('sc' in args.config) and ('sn' in args.config):
        raise ValueError("When specifying --config / -c, only one of sc and sn can be specified at a time.")
    where_abs = os.path.abspath(args.where)
    new_proj(sc_dir, args.name, where_abs, args.sub, args.config)

  # run scprocess
  elif args.subcommand == "run":
    # set default rule to all
    if args.rule == "":
      rule    = "all"
    else:
      rule = args.rule  
    
    # select snakefile corresponding to workflow
    if rule == "zoom":
      snakefile = sc_dir / "rules/zoom.smk"
    else:
      snakefile = sc_dir / "rules/scprocess.smk"

    # sort out extra arguments
    extraargs   = []
    noindex     = args.noindex
    if args.unlock:
      extraargs.append("--unlock")
      noindex     = True
    else:
      if args.extraargs:
        extraargs.append(args.extraargs[0])
      if args.dry_run:
        extraargs.append("-np")
        noindex     = True
    
    # call bsub thing
    run_scprocess(sc_dir, args.configfile, snakefile, rule, extraargs, noindex)
  
  # plot knee for selected sample
  elif args.subcommand == 'plotknee':
    # call function
    plot_interactive_knee(args.configfile, args.kneefile, args.sample)

  else:
    # if no arguments are provided at all, print the help message
    parser.print_help()


